{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoder in PyTorch<br>\n",
    "\n",
    "Faisal Z. Qureshi     \n",
    "http://vclab.science.uoit.ca\n",
    "\n",
    "Check out excellent PyTorch tutorials by \"SherlockLiao\" at [https://github.com/L1aoXingyu/pytorch-beginner](https://github.com/L1aoXingyu/pytorch-beginner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"Found device:\", torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() == 0:\n",
    "    print(\"No GPU device found\")\n",
    "else:\n",
    "    print(\"Current cuda device is\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper code that would allow us to use gpu and cpu seemlessly, I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cudafy:\n",
    "    \n",
    "    def __init__(self, device=None):\n",
    "        if torch.cuda.is_available() and device:\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = 0\n",
    "    \n",
    "    def name(self):\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.cuda.get_device_name(self.device)\n",
    "        return 'Cuda is not available.'\n",
    "    \n",
    "    def put(self, x):\n",
    "        \"\"\"Put x on the default cuda device.\"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            return x.to(device=self.device)\n",
    "        return x\n",
    "    def __call__(self, x):\n",
    "        return self.put(x)\n",
    "    \n",
    "    def get(self,x):\n",
    "        \"\"\"Get from cpu.\"\"\"\n",
    "        if x.is_cuda:\n",
    "            return x.to(device='cpu')\n",
    "        return x\n",
    "    \n",
    "def cpu(x):\n",
    "    if x.is_cuda:\n",
    "        return x.to(device='cpu')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('../datasets', transform=my_transforms, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = cudafy()\n",
    "model = gpu(autoencoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "    \n",
    "    for data in dataloader:        \n",
    "        img, _ = data # img is a [batch_size, num_channels, 28, 28] tensor\n",
    "                      # here num_channels is 1\n",
    "        img = gpu(img)\n",
    "        \n",
    "        output = model(img) # Forward\n",
    "        loss = criterion(output, img)\n",
    "        optimizer.zero_grad() # Backward & update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch, \n",
    "                  start_epoch+num_epochs-1, \n",
    "                  loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = to_img(output.cpu().data)\n",
    "save_image(pic, 'images/image-conv_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the trained autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    img, _ = data\n",
    "    img = gpu(img)\n",
    "    \n",
    "    output = model(img)\n",
    "    \n",
    "    pic = to_img(output.cpu().data)\n",
    "    print(pic.shape)\n",
    "    break\n",
    "    \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(pic[0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing<br>\n",
    "<br>\n",
    "Ensure that you do not normalize data.  Since we get the image from dataset itself, the images are already normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[13]\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = image\n",
    "output_img = model(gpu(input_img.unsqueeze(0)))\n",
    "print(output_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle('Convolutional autoencoder')\n",
    "plt.subplot(121)\n",
    "plt.title('Input image')\n",
    "plt.imshow(image[0])\n",
    "plt.subplot(122)\n",
    "plt.title('Reconstructed image')\n",
    "plt.imshow(output_img[0,0,:,:].cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model<br>\n",
    "<br>\n",
    "Now that training is done, it is a good idea to save the trained model.<br>\n",
    "<br>\n",
    "We will save enough information that would allow us to:<br>\n",
    "<br>\n",
    "1. Use the trained model; and<br>\n",
    "2. Retrain the trained model from the place where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, filename):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    try:\n",
    "        torch.save(state, filename)\n",
    "        print('Saved checkpoint \"{}\" (epoch {})'.format(filename, epoch))\n",
    "    except:\n",
    "        print('Failed to save checkpoint \"{}\"'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filename, model, optimizer=None):\n",
    "    \"\"\"\n",
    "    Loads model and optimizer from a file.\n",
    "    \n",
    "    If optimizer is None, only loads model.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        print('Loading checkpoint \"{}\"'.format(filename))\n",
    "        try:\n",
    "            checkpoint = torch.load(filename)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            if optimizer:\n",
    "                start_epoch = checkpoint['epoch']+1\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print('Loaded checkpoint \"{}\" (epoch {})'.format(filename, start_epoch))\n",
    "        except:\n",
    "            print('Cannot load checkpoint \"{}\"'.format(filename))\n",
    "    else:\n",
    "        print('Cannot find checkpoint \"{}\"'.format(filename))\n",
    "    return model, optimizer, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'conv-ae.pt'\n",
    "save_checkpoint(model, optimizer, epoch, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are only interested in saving model weights, we can do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'conv-ae-weights.pt'\n",
    "torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model<br>\n",
    "<br>\n",
    "Recall that we do not store the structure of the model.  We simply store the weights.  So we will first create the model and then load in the weights.<br>\n",
    "<br>\n",
    "Since we do not wish to resume training, we  will not load the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'conv-ae.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gpu(autoencoder())\n",
    "model2, _, _ = load_checkpoint(filename, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference<br>\n",
    "<br>\n",
    "Now lets pass an image through the learned model and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[13]\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = image\n",
    "output_img = model2(gpu(input_img.unsqueeze(0)))\n",
    "print(output_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle('Convolutional autoencoder')\n",
    "plt.subplot(121)\n",
    "plt.title('Input image')\n",
    "plt.imshow(image[0])\n",
    "plt.subplot(122)\n",
    "plt.title('Reconstructed image')\n",
    "plt.imshow(output_img[0,0,:,:].cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume training<br>\n",
    "<br>\n",
    "We can choose to resume training, by loading the optimizer state as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'conv-ae.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = gpu(autoencoder())\n",
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3, optimizer, start_epoch = load_checkpoint(filename, model3, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[13]\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = image\n",
    "output_img = model3(gpu(input_img.unsqueeze(0)))\n",
    "print(output_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle('Convolutional autoencoder')\n",
    "plt.subplot(121)\n",
    "plt.title('Input image')\n",
    "plt.imshow(image[0])\n",
    "plt.subplot(122)\n",
    "plt.title('Reconstructed image')\n",
    "plt.imshow(output_img[0,0,:,:].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "    \n",
    "    for data in dataloader:        \n",
    "        img, _ = data # img is a [batch_size, num_channels, 28, 28] tensor\n",
    "                      # here num_channels is 1\n",
    "        img = gpu(img)\n",
    "        \n",
    "        output = model3(img) # Forward\n",
    "        loss = criterion(output, img)\n",
    "        optimizer.zero_grad() # Backward & update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch, \n",
    "                  start_epoch+num_epochs-1, \n",
    "                  loss.data.item()))\n",
    "    \n",
    "pic = to_img(output.cpu().data)\n",
    "save_image(pic, 'images/image-conv_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using part of the trained network<br>\n",
    "<br>\n",
    "Now lets assume we are interested in the encoder bit only.  I.e., we want to pass an MNIST image and wants to get its 3-dimensional encoding.  We can do it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_encoder, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(*list(model3.encoder.children())[:])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = my_encoder()\n",
    "encoding = encoder(gpu(input_img.unsqueeze(0)))\n",
    "print(cpu(encoding).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

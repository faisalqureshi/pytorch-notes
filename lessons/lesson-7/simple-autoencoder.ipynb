{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple autoencoder in PyTorch\n",
    "\n",
    "Faisal Z. Qureshi     \n",
    "http://vclab.science.uoit.ca\n",
    "\n",
    "Check out excellent PyTorch tutorials by \"SherlockLiao\" at [https://github.com/L1aoXingyu/pytorch-beginner](https://github.com/L1aoXingyu/pytorch-beginner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"Found device: {} - {}\".format(i,torch.cuda.get_device_name(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() == 0:\n",
    "    print(\"No GPU device found\")\n",
    "else:\n",
    "    print(\"Current cuda device is\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper code that would allow us to use gpu and cpu seemlessly, I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cudafy:\n",
    "    \n",
    "    def __init__(self, device=None):\n",
    "        if torch.cuda.is_available() and device:\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = 0\n",
    "    \n",
    "    def name(self):\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.cuda.get_device_name(self.device)\n",
    "        return 'Cuda is not available.'\n",
    "    \n",
    "    def put(self, x):\n",
    "        \"\"\"Put x on the default cuda device.\"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            return x.to(device=self.device)\n",
    "        return x\n",
    "    def __call__(self, x):\n",
    "        return self.put(x)\n",
    "    \n",
    "    def get(self,x):\n",
    "        \"\"\"Get from cpu.\"\"\"\n",
    "        if x.is_cuda:\n",
    "            return x.to(device='cpu')\n",
    "        return x\n",
    "    \n",
    "def cpu(x):\n",
    "    if x.is_cuda:\n",
    "        return x.to(device='cpu')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = cudafy()\n",
    "x = torch.ones((3,2))\n",
    "y = gpu(x)\n",
    "z = cpu(y)\n",
    "w = cpu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpu.name())\n",
    "print('x is not on cuda', x.is_cuda)\n",
    "print('y is on cuda (if possible)', y.is_cuda)\n",
    "print('z is taken from y, z is not on cuda', z.is_cuda)\n",
    "print('w is taken from x, w is not on cuda', w.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MNIST dataset<br>\n",
    "\n",
    "For single channel images, don't forget the trailing commas as seen below.\n",
    "\n",
    "`transforms.Normalize((0.5,),(0.5,))`<br>\n",
    "\n",
    "We normalize the MNIST images in this manner to ensure that pixel values lie between -0.5 and 0.5.  This allows us to use a sigmoid when predicting pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('../datasets', transform=my_transforms, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of dataset: ', len(dataset))\n",
    "idx = np.random.choice(len(dataset))\n",
    "x, y = dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x.squeeze())\n",
    "plt.title('idx = {}, Label = {}'.format(idx,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method `to_img` is the opposite of what `Normalize` above does to an MNIST image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make an autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(64, 12), \n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(12, 3))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(128, 28 * 28), # arbitrary values\n",
    "            nn.Tanh())               # squished between -1 and 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = cudafy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpu(autoencoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for data in dataloader:        \n",
    "        img, _ = data # img is a [batch_size, num_channels, 28, 28] tensor\n",
    "                      # here num_channels is 1\n",
    "            \n",
    "        img = img.view(img.size(0), -1) # We resize it to [batchsize, 1x28x28] tensor\n",
    "        img = gpu(Variable(img))\n",
    "        output = model(img) # Forward\n",
    "        loss = criterion(output, img)\n",
    "        optimizer.zero_grad() # Backward & update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data.item()))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, 'image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model\n",
    "\n",
    "Now that training is done, it is a good idea to save the trained model.\n",
    "\n",
    "We are interested in state_dict dictionary that contains parameters associated with each layer in the model.  Optimizer too has a state_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \" -- \" , model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name)\n",
    "    #print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch preferred approach to save the model is to use model's state_dict.<br>\n",
    "<br>\n",
    "We have commented it out, so we don't overwrite the file mistakenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'simple-ae-weights-100.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference<br>\n",
    "<br>\n",
    "Now lets pass an image through the learned model and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[1]\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "plt.figure()\n",
    "plt.imshow(image[idx])\n",
    "plt.title('idx = {}, Label = {}'.format(idx, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now pass this image through the network and see what we get.  We will have to \"normalize\" and \"de-normalize\" the data as needed.  We also use `unsqueeze_()` to create a batch of size 1.  Recall that our model expects data to be in the form: batch x ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = image\n",
    "ni.unsqueeze_(0)\n",
    "ni = ni.view(1, -1)\n",
    "print('batch x (28 x 28) = ', ni.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f torch.cuda.is_available():<br>\n",
    "   ni = Variable(ni).cuda() # Lets put this on Cuda<br>\n",
    "lse:<br>\n",
    "   ni = Variable(ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oi = model(gpu(ni))\n",
    "#print(oi.shape)\n",
    "oi_ = to_img(oi)\n",
    "#print(oi_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cpu(oi_[0,0,:,:].detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved model<br>\n",
    "<br>\n",
    "We can easily load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = cudafy()\n",
    "model2 = gpu(autoencoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following should produce garbage, since we haven't trained the model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oi = model2(gpu(ni))\n",
    "oi_ = to_img(oi)\n",
    "plt.imshow(cpu(oi_[0,0,:,:].detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load the model and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(torch.load('simple-ae-weights.pt', map_location='cpu'))\n",
    "oi = model2(gpu(ni))\n",
    "oi_ = to_img(oi)\n",
    "plt.imshow(cpu(oi_[0,0,:,:].detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when you load the model all is well in the world of autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using part of the trained network<br>\n",
    "<br>\n",
    "Now lets assume we are interested in the **encoder** stage only.  I.e., we want to pass an MNIST image and wants to get its 3-dimensional encoding.  We can do it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_encoder, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(*list(model2.encoder.children())[:])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = gpu(my_encoder())\n",
    "encoding = encoder(gpu(ni))\n",
    "print(encoding.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we only care about the **decoder** stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_decoder, self).__init__()\n",
    "        \n",
    "        self.reconstruction = nn.Sequential(*list(model2.decoder.children())[:])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.reconstruction(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.empty((1,3))\n",
    "v[0,0] = 0.01\n",
    "v[0,1] = 0.0001\n",
    "v[0,2] = 1\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = my_decoder()\n",
    "ooi = d(gpu(v))\n",
    "print(ooi.shape)\n",
    "ooi_ = to_img(ooi)\n",
    "plt.imshow(ooi_[0,0,:,:].detach())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A variational autoencoder in PyTorch\n",
    "\n",
    "Faisal Z. Qureshi     \n",
    "http://vclab.science.uoit.ca\n",
    "\n",
    "Check out excellent PyTorch tutorials by \"SherlockLiao\" at [https://github.com/L1aoXingyu/pytorch-beginner](https://github.com/L1aoXingyu/pytorch-beginner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"Found device:\", torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() == 0:\n",
    "    print(\"No GPU device found\")\n",
    "else:\n",
    "    print(\"Current cuda device is\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('../datasets', transform=my_transforms, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Variational Autoencoder<br>\n",
    "<br>\n",
    "### `reparametrize(self, mu, logvar)`<br>\n",
    "<br>\n",
    "`logvar` = $\\log \\sigma^2$    <br>\n",
    "`mu` = $\\mu$<br>\n",
    "<br>\n",
    "$$<br>\n",
    "\\begin{eqnarray}<br>\n",
    "\\sigma & = & \\exp \\left( \\frac{1}{2} \\log \\sigma^2 \\right) \\\\<br>\n",
    "& = & \\exp \\left( \\log \\sigma^{2 ^ \\frac{1}{2}} \\right) \\\\<br>\n",
    "& = & \\exp \\log \\sigma \\\\<br>\n",
    "& = & \\sigma<br>\n",
    "\\end{eqnarray}<br>\n",
    "$$<br>\n",
    "<br>\n",
    "How to generate a random from normal distribution with mean $\\mu$ and variance $\\sigma^2$?<br>\n",
    "<br>\n",
    "1. Generate $x \\sim \\mathcal{N}(0,1)$.<br>\n",
    "2. Compute $y = \\sigma x + \\mu$.  Here $y \\sim \\mathcal{N}(\\mu,\\sigma^2)$  <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class var_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(var_autoencoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 400)       # These layers will be used for encoding \n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)        # These layers will be used for decoding\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "    def encode(self, x: Variable) -> (Variable, Variable):\n",
    "        h1 = F.relu(self.fc1(x))             # h1 is 400-dimensional vector\n",
    "        return self.fc21(h1), self.fc22(h1)  # this returns two 20-dimensional vectors\n",
    "    def reparametrize(self, mu: Variable, logvar: Variable) -> Variable:\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            if torch.cuda.is_available():\n",
    "                eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "            else:\n",
    "                eps = torch.FloatTensor(std.size()).normal_()\n",
    "            eps = Variable(eps)\n",
    "            return eps.mul(std).add_(mu)         # Latent variable z is 20-dimensional \n",
    "        else:\n",
    "            return mu\n",
    "    def decode(self, z: Variable) -> Variable:\n",
    "        h3 = F.relu(self.fc3(z))             # z can be used to generate new samples\n",
    "        return torch.sigmoid(self.fc4(h3))       # remember that z ~ N(mu, var)\n",
    "    def forward(self, x: Variable) -> (Variable, Variable, Variable):                    \n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = var_autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kullback-Leibler Divergence<br>\n",
    "<br>\n",
    "A measure of how one probability distribution is different from a second, reference probability distribution.  It is also called *relative entropy.*  A KL Divergence of 0 means that the two distributions are identical.<br>\n",
    "<br>\n",
    "$$<br>\n",
    "D_{KL}(P || Q) = - \\sum_{x \\in \\mathcal{X}} P(x) \\log \\frac{Q(x)}{P(x)}<br>\n",
    "$$<br>\n",
    "<br>\n",
    "### KL Divergence of $P(x)$ and $\\mathcal{N}(0,1)$<br>\n",
    "<br>\n",
    "TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar) -> Variable:\n",
    "    #print(recon_x.shape)\n",
    "    #print(x.view(-1,784).shape)\n",
    "    #print(torch.max(recon_x))\n",
    "    #print(torch.max(x))\n",
    "    #print(torch.min(recon_x))\n",
    "    #print(torch.min(x))\n",
    "    \n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784))\n",
    "    \n",
    "    # KLD is Kullbackâ€“Leibler divergence -- how much does one learned\n",
    "    # distribution deviate from another, in this specific case the\n",
    "    # learned distribution from the unit Gaussian\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    #\n",
    "    # - D_{KL} = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # note the negative D_{KL} in appendix B of the paper\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    KLD /= batch_size * 784\n",
    "    \n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 4\n",
    "num_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        image, _ = data\n",
    "        image = image.to(device)\n",
    "        \n",
    "        recon, mu, logvar = model(image)        \n",
    "        loss = loss_function(recon, image, mu, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch, \n",
    "                  start_epoch+num_epochs-1, \n",
    "                  loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = to_img(recon.cpu().data)\n",
    "save_image(pic, 'images/image-conv_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    img, _ = data\n",
    "    img = img.to(device)\n",
    "    \n",
    "    output, _, _ = model(img)\n",
    "    \n",
    "    pic = to_img(output.cpu().data)\n",
    "    print(pic.shape)\n",
    "    break\n",
    "    \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(pic[0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing<br>\n",
    "<br>\n",
    "Ensure that you do not normalize data.  Since we get the image from dataset itself, the images are already normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[867]\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = image\n",
    "output_img, _, _ = model(input_img.unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle('Convolutional autoencoder')\n",
    "plt.subplot(121)\n",
    "plt.title('Input image')\n",
    "plt.imshow(image[0])\n",
    "plt.subplot(122)\n",
    "plt.title('Reconstructed image')\n",
    "plt.imshow(output_img[0,:].view(28,28).cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model<br>\n",
    "<br>\n",
    "Now that training is done, it is a good idea to save the trained model.<br>\n",
    "<br>\n",
    "We will save enough information that would allow us to:<br>\n",
    "<br>\n",
    "1. Use the trained model; and<br>\n",
    "2. Retrain the trained model from the place where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, filename):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    try:\n",
    "        torch.save(state, filename)\n",
    "        print('Saved checkpoint \"{}\" (epoch {})'.format(filename, epoch))\n",
    "    except:\n",
    "        print('Failed to save checkpoint \"{}\"'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filename, model, optimizer=None):\n",
    "    \"\"\"\n",
    "    Loads model and optimizer from a file.\n",
    "    \n",
    "    If optimizer is None, only loads model.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        print('Loading checkpoint \"{}\"'.format(filename))\n",
    "        try:\n",
    "            checkpoint = torch.load(filename)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            if optimizer:\n",
    "                start_epoch = checkpoint['epoch']+1\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print('Loaded checkpoint \"{}\" (epoch {})'.format(filename, start_epoch))\n",
    "        except:\n",
    "            print('Cannot load checkpoint \"{}\"'.format(filename))\n",
    "    else:\n",
    "        print('Cannot find checkpoint \"{}\"'.format(filename))\n",
    "    return model, optimizer, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'conv-vae.pt'\n",
    "save_checkpoint(model, optimizer, epoch, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model<br>\n",
    "<br>\n",
    "Recall that we do not store the structure of the model.  We simply store the weights.  So we will first create the model and then load in the weights.<br>\n",
    "<br>\n",
    "Since we do not wish to resume training, we  will not load the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'conv-vae.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = var_autoencoder().to(device)\n",
    "model2, _, _ = load_checkpoint(filename, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference<br>\n",
    "<br>\n",
    "Now lets pass an image through the learned model and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = image\n",
    "output_img, _, _ = model2(input_img.unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle('Convolutional autoencoder')\n",
    "plt.subplot(121)\n",
    "plt.title('Input image')\n",
    "plt.imshow(image[0])\n",
    "plt.subplot(122)\n",
    "plt.title('Reconstructed image')\n",
    "plt.imshow(output_img[0,:].view(28,28).cpu().detach())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

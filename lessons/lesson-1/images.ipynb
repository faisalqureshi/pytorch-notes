{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images and computing relevant statistics\n",
    "\n",
    "Faisal Z. Qureshi     \n",
    "http://vclab.science.uoit.ca\n",
    "\n",
    "You can find excellent documentation for Pytorch at [https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images\n",
    "\n",
    "- [PIL image concepts](https://pillow.readthedocs.io/en/stable/handbook/concepts.html).\n",
    "- [Numpy image concepts](https://scikit-image.org/docs/dev/user_guide/numpy_images.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an RGBA image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './3063.jpg'\n",
    "image = Image.open(filename)\n",
    "print('Image:', image.size, image.getbands())\n",
    "plt.imshow(image)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a single channel image (mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './3063.png'\n",
    "image = Image.open(filename)\n",
    "print('Image:', image.size, image.getbands())\n",
    "plt.imshow(image)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an RGBA image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './frog.png'\n",
    "image = Image.open(filename)\n",
    "print('Image:', image.size, image.getbands())\n",
    "plt.imshow(image)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './soldiers.jpg'\n",
    "image = Image.open(filename)\n",
    "print('Image:', image.size, image.getbands())\n",
    "plt.imshow(image)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the image to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filenames = ['frog.png', '3063.png', '3063.jpg', 'soldiers.jpg']\n",
    "image = Image.open(filenames[1])\n",
    "\n",
    "numpy_im = np.array(image)\n",
    "print('Image: ', 'Numpy shape=', numpy_im.shape, ' [PIL bands=', image.getbands(),']')\n",
    "plt.imshow(numpy_im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting an image to torch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1\n",
    "\n",
    "Image -> Numpy array -> Torch tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.from_numpy(numpy_im)\n",
    "print(t.shape)\n",
    "plt.imshow(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "\n",
    "Image -> Torch tensor\n",
    "\n",
    "We use `torchvision.transforms.ToTensor()` to convert the PIL image to a tensor.  Note that torch assumes that the first dimension includes channels.  This is different from how we typically represent images.  In general we assume that the last dimension includes channels. This suggests we will have to transpose the torch tensor before we can display it using matplotlib.  Of course this assumes that tensor type is `float` and pixel values lie between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "t = transform(image)\n",
    "print(t.shape)\n",
    "\n",
    "t1= t.transpose(0,2); print(t1.shape)  # 4, h, w -> w, h, 4\n",
    "t1=t1.transpose(0,1); print(t1.shape)  # w, h, 4 -> w, h, 4\n",
    "plt.imshow(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Image Mean and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing mean and variance for red, blue and green channels.  We assume that an image is `(num_rows) x (num_columns) x (num_channels)`.  Note that num_rows refer to the height of the image, num_columns refer to the width of the image.  We will use `torch.mean` to compute mean values for each row (i.e., each channel).  This operation is routinely performed during a data preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['frog.png', '3063.png', '3063.jpg', 'soldiers.jpg']\n",
    "image = Image.open(filenames[0])\n",
    "t = transforms.Compose([transforms.ToTensor()])(image)\n",
    "plt.imshow(t.transpose(0,2).transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = t.shape[0]\n",
    "print(f'Num of channels = {n_channels}')\n",
    "\n",
    "t_flattened = t.view(-1, n_channels)\n",
    "print(t_flattened.shape)\n",
    "\n",
    "means = torch.mean(t_flattened, dim=0, keepdim=True)\n",
    "print(means)\n",
    "var = torch.var(t_flattened, dim=0, unbiased=True, keepdim=True)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = torch.sqrt(var)\n",
    "print(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_image = transforms.Normalize(means.squeeze(), std_dev.squeeze())\n",
    "normalized_t = normalize_image(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Plotting the normalized image')\n",
    "tmp = normalized_t.transpose(0,2).transpose(0,1)[:,:,:3] # This only works\n",
    "plt.imshow(tmp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See timing with and without using cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Without cuda')\n",
    "start_time_1 = time.time()\n",
    "for i in range(100):\n",
    "    tim.var()\n",
    "end_time_1 = time.time()\n",
    "print(end_time_1 - start_time_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_cuda:\n",
    "    print('With cuda')\n",
    "    tim_ = tim.cuda()\n",
    "    start_time_2 = time.time()\n",
    "    for i in range(100):\n",
    "        tim_.var()\n",
    "    end_time_2 = time.time()\n",
    "    print(end_time_2 - start_time_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

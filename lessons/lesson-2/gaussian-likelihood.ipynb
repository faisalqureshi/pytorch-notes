{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimate view of linear regression\n",
    "\n",
    "Faisal Z. Qureshi     \n",
    "http://vclab.science.uoit.ca\n",
    "\n",
    "You can find excellent documentation for Pytorch at [https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood example - 1D - Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "mean, var, skew, kurt = norm.stats(moments='mvsk')\n",
    "print (mean, var, skew, kurt)\n",
    "x = np.linspace(norm.ppf(0.001), norm.ppf(0.999), 100)\n",
    "ax.plot(x, norm.pdf(x),'r-', lw=5, alpha=0.6, label='norm pdf')\n",
    "plt.title('Gaussian')\n",
    "plt.savefig('gaussian.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3 = 1, .5, 1.5\n",
    "\n",
    "max_likelihood = -1\n",
    "best_mu = 0\n",
    "for mu in np.linspace(-5, 5, 100):\n",
    "    likelihood = norm.pdf(x1-mu) * norm.pdf(x2-mu) * norm.pdf(x3-mu)\n",
    "    \n",
    "    if likelihood > max_likelihood:\n",
    "        max_likelihood = likelihood\n",
    "        best_mu = mu\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1);\n",
    "    ax.axis([-5, 5, 0, 1]);\n",
    "    ax.text(-4.5, .9, 'mu = %f' % mu);\n",
    "    ax.text(-4.5, .8, 'likeliehood = %f' % likelihood);\n",
    "    ax.plot(x1, 0, 'bo', label='x1');\n",
    "    ax.plot(x2, 0, 'ro', label='x2');\n",
    "    ax.plot(x3, 0, 'go', label='x3');\n",
    "    ax.plot(x+mu, norm.pdf(x), lw=5, alpha=.5);\n",
    "    display.clear_output(wait=True);\n",
    "    display.display(plt.gcf());\n",
    "    time.sleep(0.025);\n",
    "    plt.clf();\n",
    "    \n",
    "fig, ax = plt.subplots(1,1);\n",
    "ax.axis([-5, 5, 0, 1]);\n",
    "ax.text(-4.5, .9, 'best_mu = %f' % best_mu);\n",
    "ax.text(-4.5, .8, 'max_likeliehood = %f' % max_likelihood);\n",
    "ax.plot(x1, 0, 'bo', label='x1');\n",
    "ax.plot(x2, 0, 'ro', label='x2');\n",
    "ax.plot(x3, 0, 'go', label='x3');\n",
    "ax.plot(x+best_mu, norm.pdf(x), lw=5, alpha=.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE view of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_linear_regression_data(x_start, x_end, m, c, mu, sigma, n):\n",
    "    \"\"\"\n",
    "    Generates (x,y) data that can be used for linear regression.\n",
    "    \n",
    "    Samples points around a line defined by y = mx + c and add noise ~ N(mu, sigma) \n",
    "    x_start and x_end specify the x extants\n",
    "    \n",
    "    Return values:\n",
    "        Return x, and y\n",
    "    \"\"\"\n",
    "    x = np.linspace(x_start,x_end,n)\n",
    "    y = m * x + c\n",
    "    y = y + np.random.normal(mu, sigma, n)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, c = .5, 2\n",
    "x_start, x_end = 5, 15\n",
    "mu, sigma = 0, 1\n",
    "n = 10\n",
    "\n",
    "x, y = generate_linear_regression_data(x_start, x_end, m, c, mu, sigma, n)    \n",
    "    \n",
    "plt.title('Noisy y vs. x')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis([0,20,0,12])\n",
    "plt.plot(x,y,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mle_variance_linear_regression(x, y, t0, t1):\n",
    "    err = (np.sum((y - t0 - t1 * x)**2)) / float(len(x))\n",
    "    return err*2\n",
    "\n",
    "def linear_regression_vector_calculus(x, y):\n",
    "    X = np.ones([len(x), 2])\n",
    "    X[:,1] = x\n",
    "    Y = np.ones([len(y), 1])\n",
    "    Y[:,0] = y\n",
    "\n",
    "    XtX = np.dot(X.T, X)\n",
    "    XtY = np.dot(X.T, Y)\n",
    "\n",
    "    theta = np.dot(np.linalg.inv(XtX), XtY)\n",
    "    return theta[0], theta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, t1 = linear_regression_vector_calculus(x, y)\n",
    "y_estimate = t0 + t1*np.linspace(0,20,100)\n",
    "var = mle_variance_linear_regression(x, y, t0, t1)\n",
    "\n",
    "plt.title('Estimated y vs. x')\n",
    "plt.text(2, 11, 'Using vector calculus')\n",
    "plt.text(2, 10, '$\\Theta$: (%f, %f)' % (t0, t1))\n",
    "plt.text(2, 9, 'var: %f' % var)\n",
    "plt.axis([0,20,0,12])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(x,y,'b.')\n",
    "#plt.plot(np.linspace(0,20,100),y_estimate,'r')\n",
    "plt.errorbar(np.linspace(0,20,10), t0 + t1*np.linspace(0,20,10), yerr=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

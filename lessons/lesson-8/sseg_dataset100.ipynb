{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get -r --no-parent -nH -R '*\\?C=*' --cut-dirs=1 http://vclab.science.uoit.ca/datasets/sseg-dataset100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_filelist(folder, extension):\n",
    "    files = []\n",
    "    filelist = os.listdir(folder)\n",
    "    for file in filelist[:]:\n",
    "        if file.endswith(extension):\n",
    "            files.append(file)\n",
    "    return sorted(files), folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(data):\n",
    "    # Just to confirm that the tuple filenames match\n",
    "    for k in data[:]:\n",
    "        if os.path.splitext(k[0])[0] != os.path.splitext(k[1])[0]:\n",
    "            print('Files {} and {} don\\'t match. IGNORING!'.format(k[0], k[1]))\n",
    "            data.remove(k)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmentationDataset100(Dataset):\n",
    "    \"\"\"Constructs SemanticSegmentationDataset100 from images available\n",
    "    in a folder.\n",
    "    \n",
    "    This assumes that images are 'folder/image/*.jpg' and masks are\n",
    "    'folder/ground-truth/*.png'.\n",
    "    \n",
    "    Images and masks are matched using their filenames.\"\"\"\n",
    "    def __init__(self, folder, transform, size=(256,256), verbose=False):\n",
    "        super().__init__()\n",
    "        images, self.image_folder = mk_filelist(folder=os.path.join(folder,'image'), extension='.jpg')\n",
    "        masks, self.masks_folder = mk_filelist(folder=os.path.join(folder,'ground-truth'), extension='.png')\n",
    "        self.filelist = sanitize(list(zip(images, masks)))\n",
    "        self.num_images = len(self.filelist)\n",
    "        self.data = []\n",
    "        print('Found {} images'.format(self.num_images))\n",
    "        if verbose:\n",
    "            print('Image folder {}'.format(self.image_folder))\n",
    "            print('Masks folder {}'.format(self.masks_folder))\n",
    "\n",
    "        # Unique labels found in the dataset\n",
    "        unique = set()\n",
    "        accum = torch.zeros([3,256,256])\n",
    "        for i,m in self.filelist:\n",
    "            if verbose: print('Loading image {} and mask {}'.format(i, m))\n",
    "            # Images are in jpg format\n",
    "            image = Image.open(os.path.join(self.image_folder, i))\n",
    "            image = transform(image.resize(size))\n",
    "            accum.add_(image)\n",
    "            # Masks are in png format\n",
    "            mask_raw = Image.open(os.path.join(self.masks_folder, m))\n",
    "            mask_raw = mask_raw.resize(size)\n",
    "            # I noticed that for this dataset, the pixels are \n",
    "            # not labelled using in terms of classes.  We no create our \n",
    "            # own masks where each pixel will contain the correct\n",
    "            # class labels. \n",
    "            mask = (np.array(mask_raw)*255.).astype(int)\n",
    "            unique = unique.union(mask.flatten())\n",
    "            self.data.append(\n",
    "                {\n",
    "                    'img_data': image,\n",
    "                    'mask_raw': transform(mask_raw),\n",
    "                    'mask': mask\n",
    "                }\n",
    "            )\n",
    "        self.sums = torch.sum(accum, dim=(1,2)) / (len(self.data)*size[0]*size[1])\n",
    " \n",
    "        print('Num. of classes', len(unique))\n",
    "        labels = range(len(unique))\n",
    "        mapping = list(zip(unique, labels))\n",
    "        for i in range(len(self.data)):\n",
    "            mask = self.data[i]['mask']\n",
    "            for j in mapping:\n",
    "                mask[mask == j[0]] = j[1]\n",
    "            self.data[i]['mask'] = torch.tensor(mask.astype(int)).unsqueeze(0)\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

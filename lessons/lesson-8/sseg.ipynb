{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation\n",
    "\n",
    "Faisal Qureshi  \n",
    "http://www.vclab.ca    \n",
    "faisal.qureshi@uoit.ca\n",
    "\n",
    "Check out the companion [sseg.py](./sseg.py) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sseg_dataset100 as dataset\n",
    "from torchvision import transforms\n",
    "from utils import split_train_and_validation\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Constructs SemanticSegmentationDataset100 from images available in a folder.\n",
    "\n",
    "This assumes that images are 'folder/image/*.jpg' and masks are 'folder/ground-truth/*.png'. Images and masks are matched using their filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Users/faisal/Google Drive File Stream/My Drive/Datasets/a-benchmark-for-semantic-image-segmentation/Semantic dataset100'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = dataset.SemanticSegmentationDataset100(folder=folder, size=(256,256), transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "\n",
    "image = np.transpose(dataset[i]['img_data'].numpy(), (1,2,0))\n",
    "mask_raw = dataset[i]['mask_raw'].numpy().squeeze()\n",
    "mask = dataset[i]['mask'].squeeze()\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.subplot(131)\n",
    "plt.title('Image')\n",
    "plt.imshow(image)\n",
    "plt.subplot(132)\n",
    "plt.title('Mask raw')\n",
    "plt.imshow(mask_raw)\n",
    "plt.subplot(133)\n",
    "plt.title('Mask classes')\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up train and validation data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, validation_indices = split_train_and_validation(dataset)\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=8, sampler=train_sampler)\n",
    "valiation_loader = DataLoader(dataset, batch_size=8, sampler=validation_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "x = dataset[i]['img_data']\n",
    "print(x.shape)\n",
    "y = x.view(-1, 256*256)\n",
    "print(y.shape)\n",
    "m = torch.tensor([10.,100.,1000.]).unsqueeze(-1)\n",
    "print(m.shape)\n",
    "torch.sum(torch.pow(y - m, 2), dim=(1))/(256*256)\n",
    "\n",
    "#y[0,:] = y[0,:] - m[0]\n",
    "#y[1,:] = y[1,:] - m[1]\n",
    "#y[2,:] = y[2,:] - m[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SSegNet(nn.Module):\n",
    "    \"\"\"Assumes that input images are 3-channel 256x256.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SSegNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xx\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
